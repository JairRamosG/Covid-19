{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "18ef090c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType\n",
    "from pyspark.sql.functions import col, when, sum as spark_sum\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9bc530",
   "metadata": {},
   "source": [
    "# Buscar una relación entre el Covid y las \"Cormobilidades\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cbea53",
   "metadata": {},
   "source": [
    "### Descomprimir el zip para no guardarlo en el git\n",
    "\n",
    "Ese lo tengo guardado en una carpeta en el escritorio:\n",
    "- Datos/Covid_limpio.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8ba67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: [Errno 2] No such file or directory: 'archivo.zip'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def descomprimir_zip(ruta_zip, carpeta_destino):\n",
    "    # Crear carpeta si no existe\n",
    "    os.makedirs(carpeta_destino, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        with zipfile.ZipFile(ruta_zip, 'r') as archivo_zip:\n",
    "            # Extraer todo\n",
    "            archivo_zip.extractall(carpeta_destino)\n",
    "            \n",
    "            # Mostrar información\n",
    "            print(f\"Archivo descomprimido: {ruta_zip}\")\n",
    "            return True\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "descomprimir_zip(\"archivo.zip\", \"Data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afc2709",
   "metadata": {},
   "source": [
    "### Creción de un schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72464a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_esquema = StructType([\n",
    "    StructField('FECHA_ACTUALIZACION', DateType(), True),\n",
    "    StructField('ID_REGISTRO', StringType(), True),\n",
    "    StructField('ORIGEN', StringType(), True),\n",
    "    StructField('SECTOR', StringType(), True),\n",
    "    StructField('ENTIDAD_UM', IntegerType(), True),\n",
    "    StructField('SEXO', IntegerType(), True),\n",
    "    StructField('ENTIDAD_NAC', IntegerType(), True),\n",
    "    StructField('ENTIDAD_RES', IntegerType(), True),\n",
    "    StructField('MUNICIPIO_RES', IntegerType(), True),\n",
    "    StructField('FECHA_INGRESO', DateType(), True),\n",
    "    StructField('FECHA_SINTOMAS', DateType(), True),\n",
    "    StructField('FECHA_DEF', DateType(), True),\n",
    "    StructField('INTUBADO', IntegerType(), True),\n",
    "    StructField('NEUMONIA', IntegerType(), True),\n",
    "    StructField('EDAD', IntegerType(), True),\n",
    "    StructField('NACIONALIDAD', IntegerType(), True),\n",
    "    StructField('EMBARAZO', IntegerType(), True),\n",
    "    StructField('HABLA_LENGUA_INDIG', IntegerType(), True),\n",
    "    StructField('INDIGENA', IntegerType(), True),\n",
    "    StructField('DIABETES', IntegerType(), True),\n",
    "    StructField('ASMA', IntegerType(), True),\n",
    "    StructField('INMUSUPR', IntegerType(), True),\n",
    "    StructField('HIPERTENSION', IntegerType(), True),\n",
    "    StructField('OTRA_COM', IntegerType(), True),\n",
    "    StructField('CARDIOVASCULAR', IntegerType(), True),\n",
    "    StructField('OBESIDAD', IntegerType(), True),\n",
    "    StructField('RENAL_CRONICA', IntegerType(), True),\n",
    "    StructField('OTRO_CASO', IntegerType(), True),\n",
    "    StructField('TOMA_MUESTRA_LAB', IntegerType(), True),\n",
    "    StructField('RESULTADO_LAB', IntegerType(), True),\n",
    "    StructField('TOMA_MUESTRA_ANTIGENO', IntegerType(), True),\n",
    "    StructField('RESULTADO_ANTIGENO', IntegerType(), True),\n",
    "    StructField('CLASIFICACION_FINAL', IntegerType(), True),\n",
    "    StructField('MIGRANTE', IntegerType(), True),\n",
    "    StructField('PAIS_NACIONALIDAD', StringType(), True),\n",
    "    StructField('PAIS_ORIGEN', StringType(), True),\n",
    "    StructField('UCI', IntegerType(), True)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "516783fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/06 18:19:16 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 40, schema size: 37\n",
      "CSV file: file:///home/jair/Escritorio/Big%20Data/Proyectos/Covid/Data/Covid_limpio.csv\n",
      "[Stage 38:====================================================>   (13 + 1) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+------+------+----------+----+-----------+-----------+-------------+-------------+--------------+---------+--------+--------+----+------------+--------+------------------+--------+--------+----+--------+------------+--------+--------------+--------+-------------+---------+----------------+-------------+---------------------+------------------+-------------------+--------+-----------------+-----------+---+\n",
      "|FECHA_ACTUALIZACION|ID_REGISTRO|ORIGEN|SECTOR|ENTIDAD_UM|SEXO|ENTIDAD_NAC|ENTIDAD_RES|MUNICIPIO_RES|FECHA_INGRESO|FECHA_SINTOMAS|FECHA_DEF|INTUBADO|NEUMONIA|EDAD|NACIONALIDAD|EMBARAZO|HABLA_LENGUA_INDIG|INDIGENA|DIABETES|ASMA|INMUSUPR|HIPERTENSION|OTRA_COM|CARDIOVASCULAR|OBESIDAD|RENAL_CRONICA|OTRO_CASO|TOMA_MUESTRA_LAB|RESULTADO_LAB|TOMA_MUESTRA_ANTIGENO|RESULTADO_ANTIGENO|CLASIFICACION_FINAL|MIGRANTE|PAIS_NACIONALIDAD|PAIS_ORIGEN|UCI|\n",
      "+-------------------+-----------+------+------+----------+----+-----------+-----------+-------------+-------------+--------------+---------+--------+--------+----+------------+--------+------------------+--------+--------+----+--------+------------+--------+--------------+--------+-------------+---------+----------------+-------------+---------------------+------------------+-------------------+--------+-----------------+-----------+---+\n",
      "+-------------------+-----------+------+------+----------+----+-----------+-----------+-------------+-------------+--------------+---------+--------+--------+----+------------+--------+------------------+--------+--------+----+--------+------------+--------+--------------+--------+-------------+---------+----------------+-------------+---------------------+------------------+-------------------+--------+-----------------+-----------+---+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('COVID19').config(\"spark.executor.memory\", \"4g\").config(\"spark.driver.memory\", \"4g\").getOrCreate()\n",
    "\n",
    "ruta = 'Data/Covid_limpio.csv'\n",
    "df = spark.read.csv(\n",
    "    ruta,\n",
    "    header = True,\n",
    "    schema = mi_esquema,    # evita que Spark adivine tipos (así no se confunde)\n",
    "    mode = \"DROPMALFORMED\", # elimina filas corruptas desde el inicio\n",
    "    multiLine = False,      # evita que las comas o saltos de línea rompan filas\n",
    "    escape=\"\\\"\",          # ignora comillas mal cerradas\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9aa73de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/06 18:21:02 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "[Stage 40:===============================================>        (16 + 3) / 19]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+------+------+----------+----+-----------+-----------+-------------+-------------+-------------+--------------+----------+--------+--------+----+------------+--------+------------------+--------+--------+----+----+--------+------------+--------+--------------+--------+-------------+----------+---------+----------------+-------------+---------------------+------------------+-------------------+--------+-----------------+-----------+---+\n",
      "|FECHA_ACTUALIZACION|ID_REGISTRO|ORIGEN|SECTOR|ENTIDAD_UM|SEXO|ENTIDAD_NAC|ENTIDAD_RES|MUNICIPIO_RES|TIPO_PACIENTE|FECHA_INGRESO|FECHA_SINTOMAS| FECHA_DEF|INTUBADO|NEUMONIA|EDAD|NACIONALIDAD|EMBARAZO|HABLA_LENGUA_INDIG|INDIGENA|DIABETES|EPOC|ASMA|INMUSUPR|HIPERTENSION|OTRA_COM|CARDIOVASCULAR|OBESIDAD|RENAL_CRONICA|TABAQUISMO|OTRO_CASO|TOMA_MUESTRA_LAB|RESULTADO_LAB|TOMA_MUESTRA_ANTIGENO|RESULTADO_ANTIGENO|CLASIFICACION_FINAL|MIGRANTE|PAIS_NACIONALIDAD|PAIS_ORIGEN|UCI|\n",
      "+-------------------+-----------+------+------+----------+----+-----------+-----------+-------------+-------------+-------------+--------------+----------+--------+--------+----+------------+--------+------------------+--------+--------+----+----+--------+------------+--------+--------------+--------+-------------+----------+---------+----------------+-------------+---------------------+------------------+-------------------+--------+-----------------+-----------+---+\n",
      "|         2022-07-20|     z3bf80|     2|    12|         8|   2|          8|          8|           37|            1|   2020-07-28|    2020-07-20|9999-99-99|      97|       2|  35|           1|      97|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               1|            1|                    2|                97|                  3|      99|          MÃ©xico|         97| 97|\n",
      "|         2022-07-20|     z1e370|     1|    12|        14|   1|         14|         14|           85|            1|   2020-04-22|    2020-04-18|9999-99-99|      97|       2|  42|           1|       2|                 2|       2|       2|   2|   1|       2|           2|       2|             2|       2|            2|         2|        2|               1|            2|                    2|                97|                  7|      99|          MÃ©xico|         97| 97|\n",
      "|         2022-07-20|     zze974|     1|     6|        24|   1|         24|         24|           35|            1|   2021-02-28|    2021-02-20|9999-99-99|      97|      99|  34|           1|       2|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        1|               1|            2|                    2|                97|                  7|      99|          MÃ©xico|         97| 97|\n",
      "|         2022-07-20|     zz7067|     1|    12|         9|   2|          9|          9|            7|            1|   2020-08-18|    2020-08-17|9999-99-99|      97|       2|  51|           1|      97|                 2|       2|       2|   2|   2|       2|           1|       2|             2|       2|            2|         2|        2|               1|            2|                    2|                97|                  7|      99|          MÃ©xico|         97| 97|\n",
      "|         2022-07-20|     z1da1e|     1|    12|         1|   2|          1|          1|            1|            1|   2020-03-09|    2020-03-05|9999-99-99|      97|      99|  30|           1|      97|                 1|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        1|               1|            2|                    2|                97|                  7|      99|          MÃ©xico|         97| 97|\n",
      "|         2022-07-20|     z393a3|     1|    12|         9|   1|          9|          9|           17|            1|   2020-12-28|    2020-12-28|9999-99-99|      97|       2|  47|           1|       2|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        1|               2|           97|                    1|                 2|                  7|      99|          MÃ©xico|         97| 97|\n",
      "|         2022-07-20|     z59dea|     1|    12|         7|   2|          7|          7|           78|            1|   2020-06-28|    2020-06-24|9999-99-99|      97|       2|  47|           1|      97|                 2|       2|       2|   2|   2|       2|           1|       2|             2|       2|            2|         2|        2|               2|           97|                    2|                97|                  6|      99|          MÃ©xico|         97| 97|\n",
      "|         2022-07-20|     z5ba5b|     2|    12|         8|   2|         10|          8|           37|            1|   2020-07-31|    2020-07-28|9999-99-99|      97|       2|  38|           1|      97|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               1|            2|                    2|                97|                  7|      99|          MÃ©xico|         97| 97|\n",
      "|         2022-07-20|     z2eace|     1|     3|        15|   1|         15|         15|          106|            2|   2020-09-23|    2020-09-20|9999-99-99|       2|       2|   7|           1|       2|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       1|            2|         2|        2|               1|            4|                    2|                97|                  6|      99|          MÃ©xico|         97|  2|\n",
      "|         2022-07-20|     z38de4|     1|    12|         7|   1|          7|          7|          101|            1|   2020-05-23|    2020-05-20|9999-99-99|      97|       2|   7|           1|       2|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               2|           97|                    2|                97|                  6|      99|          MÃ©xico|         97| 97|\n",
      "|         2022-07-20|     z579ac|     1|    12|        15|   2|         15|         15|           60|            1|   2020-10-14|    2020-10-10|9999-99-99|      97|       2|  33|           1|      97|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               1|            4|                    2|                97|                  6|      99|          MÃ©xico|         97| 97|\n",
      "|         2022-07-20|     z2669f|     2|    12|        14|   2|         14|         14|           39|            1|   2020-06-18|    2020-06-16|9999-99-99|      97|       2|  43|           1|      97|                 2|       2|       2|   2|   1|       2|           2|       2|             2|       2|            2|         1|        1|               1|            2|                    2|                97|                  7|      99|          MÃ©xico|         97| 97|\n",
      "|         2022-07-20|     z54912|     1|    12|        31|   1|         31|         31|           79|            1|   2020-06-12|    2020-06-10|9999-99-99|      97|       2|  56|           1|       2|                 2|       2|       1|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               1|            1|                    2|                97|                  3|      99|          MÃ©xico|         97| 97|\n",
      "|         2022-07-20|     z35a05|     1|    12|        31|   1|         31|         31|          102|            1|   2020-06-18|    2020-06-17|9999-99-99|      97|       2|  40|           1|       2|                 1|       1|       2|   2|   2|       2|           2|       2|             2|       1|            2|         2|        2|               1|            2|                    2|                97|                  7|      99|          MÃ©xico|         97| 97|\n",
      "|         2022-07-20|     z3f33c|     1|    12|         7|   1|          7|          7|          101|            1|   2020-03-29|    2020-03-27|9999-99-99|      97|       2|  67|           1|       2|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               2|           97|                    2|                97|                  6|      99|          MÃ©xico|         97| 97|\n",
      "|         2022-07-20|     z552ac|     1|    12|         1|   1|          9|          1|            1|            1|   2020-06-02|    2020-05-30|9999-99-99|      97|       2|  58|           1|       2|                 2|       2|       1|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               1|            1|                    2|                97|                  3|      99|          MÃ©xico|         97| 97|\n",
      "|         2022-07-20|     z59bbc|     1|    12|        31|   1|         31|         31|           89|            1|   2020-10-16|    2020-10-15|9999-99-99|      97|       2|  32|           1|       2|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               1|            2|                    2|                97|                  7|      99|          MÃ©xico|         97| 97|\n",
      "|         2022-07-20|     z59345|     1|    12|        31|   2|         31|         31|           89|            1|   2020-07-01|    2020-06-30|9999-99-99|      97|       2|  37|           1|      97|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               1|            1|                    2|                97|                  3|      99|          MÃ©xico|         97| 97|\n",
      "|         2022-07-20|     zzf571|     1|     6|        24|   1|         28|         24|           28|            1|   2020-06-16|    2020-06-16|9999-99-99|      97|       2|  64|           1|       2|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               1|            2|                    2|                97|                  7|      99|          MÃ©xico|         97| 97|\n",
      "|         2022-07-20|     z12d63|     2|    12|         9|   2|          9|          9|           17|            1|   2020-07-06|    2020-07-01|9999-99-99|      97|       2|  62|           1|      97|                99|      99|       2|   2|   2|       2|           1|       2|             2|       2|            2|         2|        2|               2|           97|                    2|                97|                  6|      99|          MÃ©xico|         97| 97|\n",
      "+-------------------+-----------+------+------+----------+----+-----------+-----------+-------------+-------------+-------------+--------------+----------+--------+--------+----+------------+--------+------------------+--------+--------+----+----+--------+------------+--------+--------------+--------+-------------+----------+---------+----------------+-------------+---------------------+------------------+-------------------+--------+-----------------+-----------+---+\n",
      "only showing top 20 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('embarazos').getOrCreate()\n",
    "\n",
    "df = spark.read.csv(\n",
    "    ruta, \n",
    "    header = True,\n",
    "    inferSchema=True,\n",
    "    mode = 'PERMISSIVE',\n",
    "    multiLine = False,\n",
    "    escape = \"\\\"\"\n",
    ")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7caece",
   "metadata": {},
   "source": [
    "## Crear la spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "559b9aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/06 18:21:39 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+------+------+----------+----+-----------+-----------+-------------+-------------+-------------+--------------+----------+--------+--------+----+------------+--------+------------------+--------+--------+----+----+--------+------------+--------+--------------+--------+-------------+----------+---------+----------------+-------------+---------------------+------------------+-------------------+--------+-----------------+-----------+---+\n",
      "|FECHA_ACTUALIZACION|ID_REGISTRO|ORIGEN|SECTOR|ENTIDAD_UM|SEXO|ENTIDAD_NAC|ENTIDAD_RES|MUNICIPIO_RES|TIPO_PACIENTE|FECHA_INGRESO|FECHA_SINTOMAS| FECHA_DEF|INTUBADO|NEUMONIA|EDAD|NACIONALIDAD|EMBARAZO|HABLA_LENGUA_INDIG|INDIGENA|DIABETES|EPOC|ASMA|INMUSUPR|HIPERTENSION|OTRA_COM|CARDIOVASCULAR|OBESIDAD|RENAL_CRONICA|TABAQUISMO|OTRO_CASO|TOMA_MUESTRA_LAB|RESULTADO_LAB|TOMA_MUESTRA_ANTIGENO|RESULTADO_ANTIGENO|CLASIFICACION_FINAL|MIGRANTE|PAIS_NACIONALIDAD|PAIS_ORIGEN|UCI|\n",
      "+-------------------+-----------+------+------+----------+----+-----------+-----------+-------------+-------------+-------------+--------------+----------+--------+--------+----+------------+--------+------------------+--------+--------+----+----+--------+------------+--------+--------------+--------+-------------+----------+---------+----------------+-------------+---------------------+------------------+-------------------+--------+-----------------+-----------+---+\n",
      "|         2022-07-20|     z3bf80|     2|    12|         8|   2|          8|          8|           37|            1|   2020-07-28|    2020-07-20|9999-99-99|      97|       2|  35|           1|      97|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               1|            1|                    2|                97|                  3|      99|          MÃ©xico|         97| 97|\n",
      "|         2022-07-20|     z1e370|     1|    12|        14|   1|         14|         14|           85|            1|   2020-04-22|    2020-04-18|9999-99-99|      97|       2|  42|           1|       2|                 2|       2|       2|   2|   1|       2|           2|       2|             2|       2|            2|         2|        2|               1|            2|                    2|                97|                  7|      99|          MÃ©xico|         97| 97|\n",
      "|         2022-07-20|     zze974|     1|     6|        24|   1|         24|         24|           35|            1|   2021-02-28|    2021-02-20|9999-99-99|      97|      99|  34|           1|       2|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        1|               1|            2|                    2|                97|                  7|      99|          MÃ©xico|         97| 97|\n",
      "|         2022-07-20|     zz7067|     1|    12|         9|   2|          9|          9|            7|            1|   2020-08-18|    2020-08-17|9999-99-99|      97|       2|  51|           1|      97|                 2|       2|       2|   2|   2|       2|           1|       2|             2|       2|            2|         2|        2|               1|            2|                    2|                97|                  7|      99|          MÃ©xico|         97| 97|\n",
      "|         2022-07-20|     z1da1e|     1|    12|         1|   2|          1|          1|            1|            1|   2020-03-09|    2020-03-05|9999-99-99|      97|      99|  30|           1|      97|                 1|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        1|               1|            2|                    2|                97|                  7|      99|          MÃ©xico|         97| 97|\n",
      "|         2022-07-20|     z393a3|     1|    12|         9|   1|          9|          9|           17|            1|   2020-12-28|    2020-12-28|9999-99-99|      97|       2|  47|           1|       2|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        1|               2|           97|                    1|                 2|                  7|      99|          MÃ©xico|         97| 97|\n",
      "|         2022-07-20|     z59dea|     1|    12|         7|   2|          7|          7|           78|            1|   2020-06-28|    2020-06-24|9999-99-99|      97|       2|  47|           1|      97|                 2|       2|       2|   2|   2|       2|           1|       2|             2|       2|            2|         2|        2|               2|           97|                    2|                97|                  6|      99|          MÃ©xico|         97| 97|\n",
      "|         2022-07-20|     z5ba5b|     2|    12|         8|   2|         10|          8|           37|            1|   2020-07-31|    2020-07-28|9999-99-99|      97|       2|  38|           1|      97|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               1|            2|                    2|                97|                  7|      99|          MÃ©xico|         97| 97|\n",
      "|         2022-07-20|     z2eace|     1|     3|        15|   1|         15|         15|          106|            2|   2020-09-23|    2020-09-20|9999-99-99|       2|       2|   7|           1|       2|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       1|            2|         2|        2|               1|            4|                    2|                97|                  6|      99|          MÃ©xico|         97|  2|\n",
      "|         2022-07-20|     z38de4|     1|    12|         7|   1|          7|          7|          101|            1|   2020-05-23|    2020-05-20|9999-99-99|      97|       2|   7|           1|       2|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               2|           97|                    2|                97|                  6|      99|          MÃ©xico|         97| 97|\n",
      "|         2022-07-20|     z579ac|     1|    12|        15|   2|         15|         15|           60|            1|   2020-10-14|    2020-10-10|9999-99-99|      97|       2|  33|           1|      97|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               1|            4|                    2|                97|                  6|      99|          MÃ©xico|         97| 97|\n",
      "|         2022-07-20|     z2669f|     2|    12|        14|   2|         14|         14|           39|            1|   2020-06-18|    2020-06-16|9999-99-99|      97|       2|  43|           1|      97|                 2|       2|       2|   2|   1|       2|           2|       2|             2|       2|            2|         1|        1|               1|            2|                    2|                97|                  7|      99|          MÃ©xico|         97| 97|\n",
      "|         2022-07-20|     z54912|     1|    12|        31|   1|         31|         31|           79|            1|   2020-06-12|    2020-06-10|9999-99-99|      97|       2|  56|           1|       2|                 2|       2|       1|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               1|            1|                    2|                97|                  3|      99|          MÃ©xico|         97| 97|\n",
      "|         2022-07-20|     z35a05|     1|    12|        31|   1|         31|         31|          102|            1|   2020-06-18|    2020-06-17|9999-99-99|      97|       2|  40|           1|       2|                 1|       1|       2|   2|   2|       2|           2|       2|             2|       1|            2|         2|        2|               1|            2|                    2|                97|                  7|      99|          MÃ©xico|         97| 97|\n",
      "|         2022-07-20|     z3f33c|     1|    12|         7|   1|          7|          7|          101|            1|   2020-03-29|    2020-03-27|9999-99-99|      97|       2|  67|           1|       2|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               2|           97|                    2|                97|                  6|      99|          MÃ©xico|         97| 97|\n",
      "|         2022-07-20|     z552ac|     1|    12|         1|   1|          9|          1|            1|            1|   2020-06-02|    2020-05-30|9999-99-99|      97|       2|  58|           1|       2|                 2|       2|       1|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               1|            1|                    2|                97|                  3|      99|          MÃ©xico|         97| 97|\n",
      "|         2022-07-20|     z59bbc|     1|    12|        31|   1|         31|         31|           89|            1|   2020-10-16|    2020-10-15|9999-99-99|      97|       2|  32|           1|       2|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               1|            2|                    2|                97|                  7|      99|          MÃ©xico|         97| 97|\n",
      "|         2022-07-20|     z59345|     1|    12|        31|   2|         31|         31|           89|            1|   2020-07-01|    2020-06-30|9999-99-99|      97|       2|  37|           1|      97|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               1|            1|                    2|                97|                  3|      99|          MÃ©xico|         97| 97|\n",
      "|         2022-07-20|     zzf571|     1|     6|        24|   1|         28|         24|           28|            1|   2020-06-16|    2020-06-16|9999-99-99|      97|       2|  64|           1|       2|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               1|            2|                    2|                97|                  7|      99|          MÃ©xico|         97| 97|\n",
      "|         2022-07-20|     z12d63|     2|    12|         9|   2|          9|          9|           17|            1|   2020-07-06|    2020-07-01|9999-99-99|      97|       2|  62|           1|      97|                99|      99|       2|   2|   2|       2|           1|       2|             2|       2|            2|         2|        2|               2|           97|                    2|                97|                  6|      99|          MÃ©xico|         97| 97|\n",
      "+-------------------+-----------+------+------+----------+----+-----------+-----------+-------------+-------------+-------------+--------------+----------+--------+--------+----+------------+--------+------------------+--------+--------+----+----+--------+------------+--------+--------------+--------+-------------+----------+---------+----------------+-------------+---------------------+------------------+-------------------+--------+-----------------+-----------+---+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Embarazos').getOrCreate()\n",
    "\n",
    "ruta = 'Data/Covid_limpio.csv'\n",
    "df = spark.read.csv(\n",
    "    ruta, \n",
    "    header = True,\n",
    "    inferSchema = True,\n",
    "    mode = 'PERMISSIVE',\n",
    "    multiLine = False,\n",
    "    escape = \"\\\"\"\n",
    ")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90af8db2",
   "metadata": {},
   "source": [
    "### ELiminar unas columnas de basura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abca21bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----------+----+-----------+-----------+-------------+-------------+--------+--------+----+------------+--------+------------------+--------+--------+----+----+--------+------------+--------+--------------+--------+-------------+----------+---------+----------------+-------------+---------------------+------------------+-------------------+--------+-----------------+-----------+---+\n",
      "|ORIGEN|SECTOR|ENTIDAD_UM|SEXO|ENTIDAD_NAC|ENTIDAD_RES|MUNICIPIO_RES|TIPO_PACIENTE|INTUBADO|NEUMONIA|EDAD|NACIONALIDAD|EMBARAZO|HABLA_LENGUA_INDIG|INDIGENA|DIABETES|EPOC|ASMA|INMUSUPR|HIPERTENSION|OTRA_COM|CARDIOVASCULAR|OBESIDAD|RENAL_CRONICA|TABAQUISMO|OTRO_CASO|TOMA_MUESTRA_LAB|RESULTADO_LAB|TOMA_MUESTRA_ANTIGENO|RESULTADO_ANTIGENO|CLASIFICACION_FINAL|MIGRANTE|PAIS_NACIONALIDAD|PAIS_ORIGEN|UCI|\n",
      "+------+------+----------+----+-----------+-----------+-------------+-------------+--------+--------+----+------------+--------+------------------+--------+--------+----+----+--------+------------+--------+--------------+--------+-------------+----------+---------+----------------+-------------+---------------------+------------------+-------------------+--------+-----------------+-----------+---+\n",
      "|     2|    12|         8|   2|          8|          8|           37|            1|      97|       2|  35|           1|      97|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               1|            1|                    2|                97|                  3|      99|          MÃ©xico|         97| 97|\n",
      "|     1|    12|        14|   1|         14|         14|           85|            1|      97|       2|  42|           1|       2|                 2|       2|       2|   2|   1|       2|           2|       2|             2|       2|            2|         2|        2|               1|            2|                    2|                97|                  7|      99|          MÃ©xico|         97| 97|\n",
      "|     1|     6|        24|   1|         24|         24|           35|            1|      97|      99|  34|           1|       2|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        1|               1|            2|                    2|                97|                  7|      99|          MÃ©xico|         97| 97|\n",
      "|     1|    12|         9|   2|          9|          9|            7|            1|      97|       2|  51|           1|      97|                 2|       2|       2|   2|   2|       2|           1|       2|             2|       2|            2|         2|        2|               1|            2|                    2|                97|                  7|      99|          MÃ©xico|         97| 97|\n",
      "|     1|    12|         1|   2|          1|          1|            1|            1|      97|      99|  30|           1|      97|                 1|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        1|               1|            2|                    2|                97|                  7|      99|          MÃ©xico|         97| 97|\n",
      "|     1|    12|         9|   1|          9|          9|           17|            1|      97|       2|  47|           1|       2|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        1|               2|           97|                    1|                 2|                  7|      99|          MÃ©xico|         97| 97|\n",
      "|     1|    12|         7|   2|          7|          7|           78|            1|      97|       2|  47|           1|      97|                 2|       2|       2|   2|   2|       2|           1|       2|             2|       2|            2|         2|        2|               2|           97|                    2|                97|                  6|      99|          MÃ©xico|         97| 97|\n",
      "|     2|    12|         8|   2|         10|          8|           37|            1|      97|       2|  38|           1|      97|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               1|            2|                    2|                97|                  7|      99|          MÃ©xico|         97| 97|\n",
      "|     1|     3|        15|   1|         15|         15|          106|            2|       2|       2|   7|           1|       2|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       1|            2|         2|        2|               1|            4|                    2|                97|                  6|      99|          MÃ©xico|         97|  2|\n",
      "|     1|    12|         7|   1|          7|          7|          101|            1|      97|       2|   7|           1|       2|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               2|           97|                    2|                97|                  6|      99|          MÃ©xico|         97| 97|\n",
      "|     1|    12|        15|   2|         15|         15|           60|            1|      97|       2|  33|           1|      97|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               1|            4|                    2|                97|                  6|      99|          MÃ©xico|         97| 97|\n",
      "|     2|    12|        14|   2|         14|         14|           39|            1|      97|       2|  43|           1|      97|                 2|       2|       2|   2|   1|       2|           2|       2|             2|       2|            2|         1|        1|               1|            2|                    2|                97|                  7|      99|          MÃ©xico|         97| 97|\n",
      "|     1|    12|        31|   1|         31|         31|           79|            1|      97|       2|  56|           1|       2|                 2|       2|       1|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               1|            1|                    2|                97|                  3|      99|          MÃ©xico|         97| 97|\n",
      "|     1|    12|        31|   1|         31|         31|          102|            1|      97|       2|  40|           1|       2|                 1|       1|       2|   2|   2|       2|           2|       2|             2|       1|            2|         2|        2|               1|            2|                    2|                97|                  7|      99|          MÃ©xico|         97| 97|\n",
      "|     1|    12|         7|   1|          7|          7|          101|            1|      97|       2|  67|           1|       2|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               2|           97|                    2|                97|                  6|      99|          MÃ©xico|         97| 97|\n",
      "|     1|    12|         1|   1|          9|          1|            1|            1|      97|       2|  58|           1|       2|                 2|       2|       1|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               1|            1|                    2|                97|                  3|      99|          MÃ©xico|         97| 97|\n",
      "|     1|    12|        31|   1|         31|         31|           89|            1|      97|       2|  32|           1|       2|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               1|            2|                    2|                97|                  7|      99|          MÃ©xico|         97| 97|\n",
      "|     1|    12|        31|   2|         31|         31|           89|            1|      97|       2|  37|           1|      97|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               1|            1|                    2|                97|                  3|      99|          MÃ©xico|         97| 97|\n",
      "|     1|     6|        24|   1|         28|         24|           28|            1|      97|       2|  64|           1|       2|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               1|            2|                    2|                97|                  7|      99|          MÃ©xico|         97| 97|\n",
      "|     2|    12|         9|   2|          9|          9|           17|            1|      97|       2|  62|           1|      97|                99|      99|       2|   2|   2|       2|           1|       2|             2|       2|            2|         2|        2|               2|           97|                    2|                97|                  6|      99|          MÃ©xico|         97| 97|\n",
      "+------+------+----------+----+-----------+-----------+-------------+-------------+--------+--------+----+------------+--------+------------------+--------+--------+----+----+--------+------------+--------+--------------+--------+-------------+----------+---------+----------------+-------------+---------------------+------------------+-------------------+--------+-----------------+-----------+---+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "fechas = [col for col in df.columns if 'FECHA_' in col]\n",
    "eliminar = ['ID_REGISTRO'] + fechas\n",
    "df = df.drop(*eliminar)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c40a24a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ORIGEN', 'int'),\n",
       " ('SECTOR', 'int'),\n",
       " ('ENTIDAD_UM', 'int'),\n",
       " ('SEXO', 'int'),\n",
       " ('ENTIDAD_NAC', 'int'),\n",
       " ('ENTIDAD_RES', 'int'),\n",
       " ('MUNICIPIO_RES', 'int'),\n",
       " ('TIPO_PACIENTE', 'int'),\n",
       " ('INTUBADO', 'int'),\n",
       " ('NEUMONIA', 'int'),\n",
       " ('EDAD', 'int'),\n",
       " ('NACIONALIDAD', 'int'),\n",
       " ('EMBARAZO', 'int'),\n",
       " ('HABLA_LENGUA_INDIG', 'int'),\n",
       " ('INDIGENA', 'int'),\n",
       " ('DIABETES', 'int'),\n",
       " ('EPOC', 'int'),\n",
       " ('ASMA', 'int'),\n",
       " ('INMUSUPR', 'int'),\n",
       " ('HIPERTENSION', 'int'),\n",
       " ('OTRA_COM', 'int'),\n",
       " ('CARDIOVASCULAR', 'int'),\n",
       " ('OBESIDAD', 'int'),\n",
       " ('RENAL_CRONICA', 'int'),\n",
       " ('TABAQUISMO', 'int'),\n",
       " ('OTRO_CASO', 'int'),\n",
       " ('TOMA_MUESTRA_LAB', 'int'),\n",
       " ('RESULTADO_LAB', 'int'),\n",
       " ('TOMA_MUESTRA_ANTIGENO', 'int'),\n",
       " ('RESULTADO_ANTIGENO', 'int'),\n",
       " ('CLASIFICACION_FINAL', 'int'),\n",
       " ('MIGRANTE', 'int'),\n",
       " ('PAIS_NACIONALIDAD', 'string'),\n",
       " ('PAIS_ORIGEN', 'string'),\n",
       " ('UCI', 'int')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c967325",
   "metadata": {},
   "source": [
    "### Registros por país"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65e70ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 46:==================================================>     (17 + 2) / 19]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17186451 - MÃ©xico\n",
      "51950 - Estados Unidos de AmÃ©rica\n",
      "9242 - Venezuela\n",
      "7410 - Colombia\n",
      "5059 - RepÃºblica de Honduras\n",
      "4412 - Guatemala\n",
      "3193 - Cuba\n",
      "2865 - Argentina\n",
      "2835 - Nicaragua\n",
      "2825 - EspaÃ±a\n",
      "2750 - El Salvador\n",
      "2703 - Brasil\n",
      "2165 - Alemania\n",
      "2104 - Otro\n",
      "1903 - Francia\n",
      "1847 - HaitÃ­\n",
      "1795 - CanadÃ¡\n",
      "1793 - PerÃº\n",
      "1782 - China\n",
      "1768 - Ecuador\n",
      "1427 - JapÃ³n\n",
      "1253 - Chile\n",
      "1235 - Italia\n",
      "946 - Ucrania\n",
      "780 - Bolivia\n",
      "623 - India\n",
      "488 - RepÃºblica de Corea\n",
      "451 - Gran BretaÃ±a (Reino Unido)\n",
      "423 - RepÃºblica Dominicana\n",
      "388 - Rusia\n",
      "278 - Suiza\n",
      "251 - RepÃºblica de Costa Rica\n",
      "247 - Filipinas\n",
      "235 - Belice\n",
      "232 - Holanda\n",
      "227 - RepÃºblica Oriental del Uruguay\n",
      "209 - Australia\n",
      "207 - Polonia\n",
      "183 - RepÃºblica de PanamÃ¡\n",
      "179 - Portugal\n",
      "173 - Paraguay\n",
      "146 - SE DESCONOCE\n",
      "143 - Rumania\n",
      "141 - Estado Libre Asociado de Puerto Rico\n",
      "134 - BÃ©lgica\n",
      "119 - Israel\n",
      "112 - SudÃ¡frica\n",
      "103 - Irlanda\n",
      "98 - TurquÃ­a\n",
      "95 - Austria\n",
      "92 - Dinamarca\n",
      "86 - Nigeria\n",
      "84 - RepÃºblica Checa y RepÃºblica Eslovaca\n",
      "75 - Zona Neutral\n",
      "73 - Egipto\n",
      "72 - Antigua y Bermuda\n",
      "69 - TaiwÃ¡n\n",
      "67 - LÃ­bano\n",
      "65 - Suecia\n",
      "64 - Jamaica\n",
      "62 - 99\n",
      "61 - Indonesia\n",
      "60 - HungrÃ­a\n",
      "58 - Bulgaria\n",
      "57 - RepÃºblica DemocrÃ¡tica de Corea\n",
      "53 - Nueva Zelandia\n",
      "51 - Eslovaquia\n",
      "48 - Macao\n",
      "46 - Congo\n",
      "46 - Marruecos\n",
      "44 - Noruega\n",
      "43 - Finlandia\n",
      "43 - IrÃ¡n\n",
      "41 - Argelia\n",
      "40 - Grecia\n",
      "37 - AfganistÃ¡n\n",
      "37 - Campione DItalia\n",
      "35 - Kenia\n",
      "34 - Ghana\n",
      "33 - Armenia\n",
      "32 - PakistÃ¡n\n",
      "31 - Siria\n",
      "30 - Costa de Marfil\n",
      "30 - Croacia\n",
      "29 - CamerÃºn\n",
      "29 - Estonia\n",
      "27 - Eslovenia\n",
      "27 - Lituania\n",
      "26 - Vietnam\n",
      "26 - Malasia\n",
      "25 - Georgia\n",
      "23 - Islandia\n",
      "22 - Bangladesh\n",
      "22 - Arabia Saudita\n",
      "21 - Thailandia\n",
      "20 - Camboya\n",
      "20 - Emiratos Arabes Unidos\n",
      "20 - Singapur\n",
      "19 - Myanmar\n",
      "18 - PaÃ­ses de la Ex-U.R.S.S., excepto Ucrania y Bielorusia\n",
      "17 - Nepal\n",
      "16 - Republica DemocrÃ¡tica del Congo\n",
      "16 - Iraq\n",
      "14 - Hong Kong\n",
      "14 - Bielorrusia\n",
      "14 - Estado de Bahrein\n",
      "13 - Guyana Francesa\n",
      "12 - Yemen DemocrÃ¡tica\n",
      "12 - RepÃºblica Centro Africana\n",
      "12 - GabÃ³n\n",
      "11 - Letonia\n",
      "11 - Libia\n",
      "11 - EtiopÃ­a\n",
      "11 - Malta\n",
      "10 - Togo\n",
      "10 - Mongolia\n",
      "9 - RepÃºblica de Angola\n",
      "8 - Macedonia\n",
      "8 - Uganda\n",
      "7 - NÃ­ger\n",
      "6 - Zimbabwe\n",
      "6 - Guinea\n",
      "6 - Bosnia y Herzegovina\n",
      "6 - Tanzania\n",
      "6 - Burkina Faso\n",
      "6 - Micronesia\n",
      "6 - Madeira\n",
      "6 - UzbekistÃ¡n\n",
      "6 - Estado de Kuwait\n",
      "6 - Guadalupe\n",
      "6 - Rhuanda\n",
      "6 - Reino de Swazilandia\n",
      "6 - MalÃ­\n",
      "6 - KazajstÃ¡n\n",
      "5 - Commonwealth de Dominica\n",
      "5 - RepÃºblica de Guyana\n",
      "5 - Islas VÃ­rgenes de Estados Unidos de AmÃ©rica\n",
      "5 - Senegal\n",
      "4 - Guinea Ecuatorial\n",
      "4 - Barbados\n",
      "4 - Polinesia Francesa\n",
      "4 - Islas menores alejadas de los Estados Unidos\n",
      "4 - Sahara del Oeste\n",
      "4 - Estado Independiente de Samoa Occidental\n",
      "3 - Trieste\n",
      "3 - RepÃºblica de Trinidad y Tobago\n",
      "3 - TayikistÃ¡n\n",
      "3 - Territorio BritÃ¡nico en el OcÃ©ano Indico\n",
      "3 - Burundi\n",
      "3 - AntÃ¡rtica\n",
      "3 - Commonwealth de las Bahamas\n",
      "3 - RepÃºblica de las Islas Marshall\n",
      "3 - Nueva Caledonia\n",
      "2 - Eritrea\n",
      "2 - AzerbaiyÃ¡n - Islas Azores\n",
      "2 - ArchipiÃ©lago de Svalbard\n",
      "2 - Moldavia\n",
      "2 - Islas VÃ­rgenes BritÃ¡nicas\n",
      "2 - Zaire\n",
      "2 - RepÃºblica de TÃºnez\n",
      "2 - RepÃºblica de Chipre\n",
      "2 - SudÃ¡n\n",
      "2 - Estado de Quatar\n",
      "2 - Tuvalu\n",
      "2 - Granada\n",
      "2 - Gibraltar\n",
      "2 - El Vaticano\n",
      "2 - RepÃºblica de Liberia\n",
      "2 - Benin\n",
      "2 - Mauritania\n",
      "2 - Guam\n",
      "2 - Fiji\n",
      "2 - Chad\n",
      "2 - Zambia\n",
      "2 - Niue\n",
      "2 - KirguistÃ¡n\n",
      "2 - Madagascar\n",
      "1 - Principado de MÃ³naco\n",
      "1 - RepÃºblica de Mauricio\n",
      "1 - AscensiÃ³n\n",
      "1 - Surinam\n",
      "1 - SultanÃ­a de OmÃ¡n\n",
      "1 - RepÃºblica de Albania\n",
      "1 - Sark\n",
      "1 - Somalia\n",
      "1 - Buthan\n",
      "1 - Islas CaimÃ¡n\n",
      "1 - Isla Anguilla\n",
      "1 - Botswana\n",
      "1 - PaÃ­ses de la Ex-Yugoslavia\n",
      "1 - Nevis\n",
      "1 - Groenlandia\n",
      "1 - Gambia\n",
      "1 - TurkmenistÃ¡n\n",
      "1 - Samoa Americana\n",
      "1 - Zona Especial Canaria\n",
      "1 - Martinica\n",
      "1 - Islas de Guernesey\n",
      "1 - Reino Hachemita de Jordania\n",
      "1 - ReuniÃ³n\n",
      "1 - Aruba\n",
      "1 - Palau\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result = df.groupBy(df['PAIS_NACIONALIDAD']).count().orderBy('count', ascending = False).collect()\n",
    "for row in result:\n",
    "    print(f'{row[1]} - {row[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd816401",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "antes_null = df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4f058b",
   "metadata": {},
   "source": [
    "### Eliminarle los nulos al dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb24e2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 57:==================================================>     (17 + 2) / 19]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos nulos eliminados: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = df.na.drop()\n",
    "despues_null = df.count()\n",
    "print(f'Datos nulos eliminados: {antes_null - despues_null}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e288c7b4",
   "metadata": {},
   "source": [
    "### ELIMINAR LO QUE NO QUIERO USAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d11afddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----------+----+-----------+-----------+-------------+-------------+--------+----+------------+--------+------------------+--------+--------+----+----+--------+------------+--------+--------------+--------+-------------+----------+---------+----------------+-------------+---------------------+------------------+-------------------+--------+-----------------+-----------+---+\n",
      "|ORIGEN|SECTOR|ENTIDAD_UM|SEXO|ENTIDAD_NAC|ENTIDAD_RES|MUNICIPIO_RES|TIPO_PACIENTE|NEUMONIA|EDAD|NACIONALIDAD|EMBARAZO|HABLA_LENGUA_INDIG|INDIGENA|DIABETES|EPOC|ASMA|INMUSUPR|HIPERTENSION|OTRA_COM|CARDIOVASCULAR|OBESIDAD|RENAL_CRONICA|TABAQUISMO|OTRO_CASO|TOMA_MUESTRA_LAB|RESULTADO_LAB|TOMA_MUESTRA_ANTIGENO|RESULTADO_ANTIGENO|CLASIFICACION_FINAL|MIGRANTE|PAIS_NACIONALIDAD|PAIS_ORIGEN|UCI|\n",
      "+------+------+----------+----+-----------+-----------+-------------+-------------+--------+----+------------+--------+------------------+--------+--------+----+----+--------+------------+--------+--------------+--------+-------------+----------+---------+----------------+-------------+---------------------+------------------+-------------------+--------+-----------------+-----------+---+\n",
      "|     2|    12|         8|   2|          8|          8|           37|            1|       2|  35|           1|      97|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               1|            1|                    2|                97|                  3|      99|          MÃ©xico|         97| 97|\n",
      "|     1|    12|        14|   1|         14|         14|           85|            1|       2|  42|           1|       2|                 2|       2|       2|   2|   1|       2|           2|       2|             2|       2|            2|         2|        2|               1|            2|                    2|                97|                  7|      99|          MÃ©xico|         97| 97|\n",
      "|     1|     6|        24|   1|         24|         24|           35|            1|      99|  34|           1|       2|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        1|               1|            2|                    2|                97|                  7|      99|          MÃ©xico|         97| 97|\n",
      "|     1|    12|         9|   2|          9|          9|            7|            1|       2|  51|           1|      97|                 2|       2|       2|   2|   2|       2|           1|       2|             2|       2|            2|         2|        2|               1|            2|                    2|                97|                  7|      99|          MÃ©xico|         97| 97|\n",
      "|     1|    12|         1|   2|          1|          1|            1|            1|      99|  30|           1|      97|                 1|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        1|               1|            2|                    2|                97|                  7|      99|          MÃ©xico|         97| 97|\n",
      "|     1|    12|         9|   1|          9|          9|           17|            1|       2|  47|           1|       2|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        1|               2|           97|                    1|                 2|                  7|      99|          MÃ©xico|         97| 97|\n",
      "|     1|    12|         7|   2|          7|          7|           78|            1|       2|  47|           1|      97|                 2|       2|       2|   2|   2|       2|           1|       2|             2|       2|            2|         2|        2|               2|           97|                    2|                97|                  6|      99|          MÃ©xico|         97| 97|\n",
      "|     2|    12|         8|   2|         10|          8|           37|            1|       2|  38|           1|      97|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               1|            2|                    2|                97|                  7|      99|          MÃ©xico|         97| 97|\n",
      "|     1|     3|        15|   1|         15|         15|          106|            2|       2|   7|           1|       2|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       1|            2|         2|        2|               1|            4|                    2|                97|                  6|      99|          MÃ©xico|         97|  2|\n",
      "|     1|    12|         7|   1|          7|          7|          101|            1|       2|   7|           1|       2|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               2|           97|                    2|                97|                  6|      99|          MÃ©xico|         97| 97|\n",
      "|     1|    12|        15|   2|         15|         15|           60|            1|       2|  33|           1|      97|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               1|            4|                    2|                97|                  6|      99|          MÃ©xico|         97| 97|\n",
      "|     2|    12|        14|   2|         14|         14|           39|            1|       2|  43|           1|      97|                 2|       2|       2|   2|   1|       2|           2|       2|             2|       2|            2|         1|        1|               1|            2|                    2|                97|                  7|      99|          MÃ©xico|         97| 97|\n",
      "|     1|    12|        31|   1|         31|         31|           79|            1|       2|  56|           1|       2|                 2|       2|       1|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               1|            1|                    2|                97|                  3|      99|          MÃ©xico|         97| 97|\n",
      "|     1|    12|        31|   1|         31|         31|          102|            1|       2|  40|           1|       2|                 1|       1|       2|   2|   2|       2|           2|       2|             2|       1|            2|         2|        2|               1|            2|                    2|                97|                  7|      99|          MÃ©xico|         97| 97|\n",
      "|     1|    12|         7|   1|          7|          7|          101|            1|       2|  67|           1|       2|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               2|           97|                    2|                97|                  6|      99|          MÃ©xico|         97| 97|\n",
      "|     1|    12|         1|   1|          9|          1|            1|            1|       2|  58|           1|       2|                 2|       2|       1|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               1|            1|                    2|                97|                  3|      99|          MÃ©xico|         97| 97|\n",
      "|     1|    12|        31|   1|         31|         31|           89|            1|       2|  32|           1|       2|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               1|            2|                    2|                97|                  7|      99|          MÃ©xico|         97| 97|\n",
      "|     1|    12|        31|   2|         31|         31|           89|            1|       2|  37|           1|      97|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               1|            1|                    2|                97|                  3|      99|          MÃ©xico|         97| 97|\n",
      "|     1|     6|        24|   1|         28|         24|           28|            1|       2|  64|           1|       2|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               1|            2|                    2|                97|                  7|      99|          MÃ©xico|         97| 97|\n",
      "|     2|    12|         9|   2|          9|          9|           17|            1|       2|  62|           1|      97|                99|      99|       2|   2|   2|       2|           1|       2|             2|       2|            2|         2|        2|               2|           97|                    2|                97|                  6|      99|          MÃ©xico|         97| 97|\n",
      "+------+------+----------+----+-----------+-----------+-------------+-------------+--------+----+------------+--------+------------------+--------+--------+----+----+--------+------------+--------+--------------+--------+-------------+----------+---------+----------------+-------------+---------------------+------------------+-------------------+--------+-----------------+-----------+---+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "fechas = [col for col in df.columns if 'FECHA_' in col]\n",
    "eliminar = ['ID_REGISTRO', 'INTUBADO'] + fechas\n",
    "df = df.drop(*eliminar)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d6c221",
   "metadata": {},
   "source": [
    "### Cambiarle los datos a numéricos para trabajarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3259495b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ORIGEN', 'int'),\n",
       " ('SECTOR', 'int'),\n",
       " ('ENTIDAD_UM', 'int'),\n",
       " ('SEXO', 'int'),\n",
       " ('ENTIDAD_NAC', 'int'),\n",
       " ('ENTIDAD_RES', 'int'),\n",
       " ('MUNICIPIO_RES', 'int'),\n",
       " ('TIPO_PACIENTE', 'int'),\n",
       " ('NEUMONIA', 'int'),\n",
       " ('EDAD', 'int'),\n",
       " ('NACIONALIDAD', 'int'),\n",
       " ('EMBARAZO', 'int'),\n",
       " ('HABLA_LENGUA_INDIG', 'int'),\n",
       " ('INDIGENA', 'int'),\n",
       " ('DIABETES', 'int'),\n",
       " ('EPOC', 'int'),\n",
       " ('ASMA', 'int'),\n",
       " ('INMUSUPR', 'int'),\n",
       " ('HIPERTENSION', 'int'),\n",
       " ('OTRA_COM', 'int'),\n",
       " ('CARDIOVASCULAR', 'int'),\n",
       " ('OBESIDAD', 'int'),\n",
       " ('RENAL_CRONICA', 'int'),\n",
       " ('TABAQUISMO', 'int'),\n",
       " ('OTRO_CASO', 'int'),\n",
       " ('TOMA_MUESTRA_LAB', 'int'),\n",
       " ('RESULTADO_LAB', 'int'),\n",
       " ('TOMA_MUESTRA_ANTIGENO', 'int'),\n",
       " ('RESULTADO_ANTIGENO', 'int'),\n",
       " ('CLASIFICACION_FINAL', 'int'),\n",
       " ('MIGRANTE', 'int'),\n",
       " ('PAIS_NACIONALIDAD', 'string'),\n",
       " ('PAIS_ORIGEN', 'int'),\n",
       " ('UCI', 'int')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "numericas = [col for col in df.columns if col != 'PAIS_NACIONALIDAD']\n",
    "for c in numericas:\n",
    "    df = df.withColumn(c, col(c).cast(IntegerType()))\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e273239f",
   "metadata": {},
   "source": [
    "### Preparar columnas para un análisis estadístico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64997b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_variables_cormobilidad(df):\n",
    "    condiciones = ['DIABETES', 'HIPERTENSION', 'OBESIDAD', 'ASMA', 'EPOC', 'INMUSUPR', 'RENAL_CRONICA', 'TABAQUISMO']\n",
    "\n",
    "    # Ponerles un contador\n",
    "    df = df.withColumn(\"N_CORMOBILIDADES\", \n",
    "                       when(col('DIABETES') == 1, 1).otherwise(0) +\n",
    "                       when(col('HIPERTENSION') == 1, 1).otherwise(0) + \n",
    "                       when(col('OBESIDAD') == 1, 1).otherwise(0) + \n",
    "                       when(col('ASMA') == 1, 1).otherwise(0) + \n",
    "                       when(col('EPOC') == 1, 1).otherwise(0) + \n",
    "                       when(col('INMUSUPR') == 1, 1).otherwise(0) + \n",
    "                       when(col('RENAL_CRONICA') == 1, 1).otherwise(0) + \n",
    "                       when(col('TABAQUISMO') == 1, 1).otherwise(0))\n",
    "    \n",
    "    # Ponerles una categoría\n",
    "    df = df.withColumn(\"Corm_cardiovascular\",\n",
    "                       when(col(\"HIPERTENSION\") == 1 | col(\"DIABETES\") == 1 | col(\"OBESIDAD\") == 1, 1).otherwise(0)) \n",
    "    \n",
    "    df = df.withColumn(\"Corm_respiratoria\",\n",
    "                       when(col(\"ASMA\") == 1 | col('EPOC') == 1), 1).otherwise(0)\n",
    "    \n",
    "    df = df.whithColumn('Corm_inmunosup',\n",
    "                        when(col(\"INMUSUPR\") == 1), 1).otherwise(0)\n",
    "    \n",
    "    df = df.whithColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e8b764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, sum as spark_sum\n",
    "\n",
    "def crear_variables_comorbilidad(df):\n",
    "    \"\"\"\n",
    "    Crea variables categóricas para análisis de comorbilidades.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Contador de comorbilidades por paciente\n",
    "    condiciones = ['DIABETES', 'HIPERTENSION', 'OBESIDAD', 'ASMA', \n",
    "                   'EPOC', 'INMUSUPR', 'RENAL_CRONICA', 'TABAQUISMO']\n",
    "    \n",
    "    # Inicializar contador\n",
    "    df = df.withColumn(\"NUM_COMORBILIDADES\", \n",
    "                       when(col(\"DIABETES\") == 1, 1).otherwise(0) +\n",
    "                       when(col(\"HIPERTENSION\") == 1, 1).otherwise(0) +\n",
    "                       when(col(\"OBESIDAD\") == 1, 1).otherwise(0) +\n",
    "                       when(col(\"ASMA\") == 1, 1).otherwise(0) +\n",
    "                       when(col(\"EPOC\") == 1, 1).otherwise(0) +\n",
    "                       when(col(\"INMUSUPR\") == 1, 1).otherwise(0) +\n",
    "                       when(col(\"RENAL_CRONICA\") == 1, 1).otherwise(0) +\n",
    "                       when(col(\"TABAQUISMO\") == 1, 1).otherwise(0))\n",
    "    \n",
    "    # 2. Crear categorías\n",
    "    df = df.withColumn(\"TIENE_CARDIOVASCULAR\",\n",
    "                       when((col(\"HIPERTENSION\") == 1) | \n",
    "                            (col(\"DIABETES\") == 1) | \n",
    "                            (col(\"OBESIDAD\") == 1), 1)\n",
    "                       .otherwise(0))\n",
    "    \n",
    "    df = df.withColumn(\"TIENE_RESPIRATORIA\",\n",
    "                       when((col(\"ASMA\") == 1) | \n",
    "                            (col(\"EPOC\") == 1), 1)\n",
    "                       .otherwise(0))\n",
    "    \n",
    "    df = df.withColumn(\"TIENE_INMUNOSUPRESION\",\n",
    "                       when(col(\"INMUSUPR\") == 1, 1)\n",
    "                       .otherwise(0))\n",
    "    \n",
    "    df = df.withColumn(\"TIENE_RENAL_CRONICA\",\n",
    "                       when(col(\"RENAL_CRONICA\") == 1, 1)\n",
    "                       .otherwise(0))\n",
    "    \n",
    "    # 3. Categoría de riesgo según comorbilidades\n",
    "    df = df.withColumn(\"CATEGORIA_RIESGO\",\n",
    "                       when(col(\"NUM_COMORBILIDADES\") >= 3, \"ALTO\")\n",
    "                       .when(col(\"NUM_COMORBILIDADES\") == 2, \"MEDIO\")\n",
    "                       .when(col(\"NUM_COMORBILIDADES\") == 1, \"BAJO\")\n",
    "                       .otherwise(\"NINGUNO\"))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Uso:\n",
    "df = crear_variables_comorbilidad(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181e7776",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1272093a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed2bfd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81aa4b1d",
   "metadata": {},
   "source": [
    "## Experimentar con los groupBy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a859311d",
   "metadata": {},
   "source": [
    "Quiero saber:\n",
    "\n",
    "* Cuántas mujeres hay por cada país\n",
    "* Cuántas mujeres hay en total en comparación con los hombres\n",
    "* Cuántas mujeres se infectaron y cuantas no\n",
    "* Cuántas mujeres estaban embarazadas y cuántas no\n",
    "* Cuantas de mujeres están embarazadas estaban contagiadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c129e690",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay un total de 9291799 mujeres\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 64:=====================================================>  (18 + 1) / 19]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|   PAIS_NACIONALIDAD|  count|\n",
      "+--------------------+-------+\n",
      "|             MÃ©xico|9234465|\n",
      "|Estados Unidos de...|  25705|\n",
      "|           Venezuela|   5036|\n",
      "|            Colombia|   4019|\n",
      "|RepÃºblica de Hon...|   1989|\n",
      "|           Guatemala|   1804|\n",
      "|                Cuba|   1433|\n",
      "|              Brasil|   1252|\n",
      "|         El Salvador|   1248|\n",
      "|           Argentina|   1243|\n",
      "|           Nicaragua|   1036|\n",
      "|             EspaÃ±a|   1034|\n",
      "|                Otro|    875|\n",
      "|               PerÃº|    866|\n",
      "|             Ecuador|    819|\n",
      "|              HaitÃ­|    807|\n",
      "|             CanadÃ¡|    798|\n",
      "|             Francia|    790|\n",
      "|            Alemania|    691|\n",
      "|               Chile|    558|\n",
      "+--------------------+-------+\n",
      "only showing top 20 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Cuántas mujeres hay de cada país\n",
    "'''\n",
    "n_mujeres = df.filter(df['SEXO'] == 1).count()\n",
    "print(f'Hay un total de {n_mujeres} mujeres')\n",
    "df.filter(df['SEXO'] == 1).groupBy('PAIS_NACIONALIDAD').count().orderBy('count', ascending = False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "989fe14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 73:===============================================>        (16 + 3) / 19]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La proporción de mujeres: 53.68 %\n",
      "La proporción de hombres: 46.32 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Cuántas mujeres hay en total en comparación con los hombres\n",
    "'''\n",
    "total = df.count()\n",
    "n_mujeres = df.filter(df['SEXO'] == 1).count()\n",
    "n_hombres = df.filter(df['SEXO'] == 2).count()\n",
    "\n",
    "prop_m = n_mujeres / total\n",
    "prop_h = n_hombres / total\n",
    "\n",
    "print(f'La proporción de mujeres: {np.round(prop_m * 100, 2)} %')\n",
    "print(f'La proporción de hombres: {np.round(prop_h * 100, 2)} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "03e6b659",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/06 18:24:26 WARN CacheManager: Asked to cache already cached data.\n",
      "25/12/06 18:24:26 WARN BlockManager: Putting block rdd_89_10 failed due to exception org.apache.spark.SparkNumberFormatException: [CAST_INVALID_INPUT] The value 'El Salvador' of the type \"STRING\" cannot be cast to \"INT\" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018\n",
      "== DataFrame ==\n",
      "\"cast\" was called from\n",
      "line 6 in cell [9]\n",
      ".\n",
      "25/12/06 18:24:26 WARN BlockManager: Block rdd_89_10 could not be removed as it was not found on disk or in memory\n",
      "25/12/06 18:24:26 WARN BlockManager: Putting block rdd_89_7 failed due to exception org.apache.spark.SparkNumberFormatException: [CAST_INVALID_INPUT] The value 'RepÃºblica de Honduras' of the type \"STRING\" cannot be cast to \"INT\" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018\n",
      "== DataFrame ==\n",
      "\"cast\" was called from\n",
      "line 6 in cell [9]\n",
      ".\n",
      "25/12/06 18:24:26 WARN BlockManager: Block rdd_89_7 could not be removed as it was not found on disk or in memory\n",
      "25/12/06 18:24:26 ERROR Executor: Exception in task 10.0 in stage 76.0 (TID 437)\n",
      "org.apache.spark.SparkNumberFormatException: [CAST_INVALID_INPUT] The value 'El Salvador' of the type \"STRING\" cannot be cast to \"INT\" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018\n",
      "== DataFrame ==\n",
      "\"cast\" was called from\n",
      "line 6 in cell [9]\n",
      "\n",
      "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.invalidInputInCastToNumberError(QueryExecutionErrors.scala:145)\n",
      "\tat org.apache.spark.sql.catalyst.util.UTF8StringUtils$.withException(UTF8StringUtils.scala:51)\n",
      "\tat org.apache.spark.sql.catalyst.util.UTF8StringUtils$.toIntExact(UTF8StringUtils.scala:34)\n",
      "\tat org.apache.spark.sql.catalyst.util.UTF8StringUtils.toIntExact(UTF8StringUtils.scala)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:90)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:82)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:294)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:291)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "25/12/06 18:24:26 ERROR Executor: Exception in task 7.0 in stage 76.0 (TID 434)\n",
      "org.apache.spark.SparkNumberFormatException: [CAST_INVALID_INPUT] The value 'RepÃºblica de Honduras' of the type \"STRING\" cannot be cast to \"INT\" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018\n",
      "== DataFrame ==\n",
      "\"cast\" was called from\n",
      "line 6 in cell [9]\n",
      "\n",
      "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.invalidInputInCastToNumberError(QueryExecutionErrors.scala:145)\n",
      "\tat org.apache.spark.sql.catalyst.util.UTF8StringUtils$.withException(UTF8StringUtils.scala:51)\n",
      "\tat org.apache.spark.sql.catalyst.util.UTF8StringUtils$.toIntExact(UTF8StringUtils.scala:34)\n",
      "\tat org.apache.spark.sql.catalyst.util.UTF8StringUtils.toIntExact(UTF8StringUtils.scala)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:90)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:82)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:294)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:291)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "25/12/06 18:24:26 WARN TaskSetManager: Lost task 7.0 in stage 76.0 (TID 434) (192.168.0.12 executor driver): org.apache.spark.SparkNumberFormatException: [CAST_INVALID_INPUT] The value 'RepÃºblica de Honduras' of the type \"STRING\" cannot be cast to \"INT\" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018\n",
      "== DataFrame ==\n",
      "\"cast\" was called from\n",
      "line 6 in cell [9]\n",
      "\n",
      "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.invalidInputInCastToNumberError(QueryExecutionErrors.scala:145)\n",
      "\tat org.apache.spark.sql.catalyst.util.UTF8StringUtils$.withException(UTF8StringUtils.scala:51)\n",
      "\tat org.apache.spark.sql.catalyst.util.UTF8StringUtils$.toIntExact(UTF8StringUtils.scala:34)\n",
      "\tat org.apache.spark.sql.catalyst.util.UTF8StringUtils.toIntExact(UTF8StringUtils.scala)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:90)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:82)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:294)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:291)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "\n",
      "25/12/06 18:24:26 ERROR TaskSetManager: Task 7 in stage 76.0 failed 1 times; aborting job\n",
      "25/12/06 18:24:26 WARN BlockManager: Putting block rdd_89_11 failed due to exception org.apache.spark.SparkNumberFormatException: [CAST_INVALID_INPUT] The value 'RepÃºblica de Honduras' of the type \"STRING\" cannot be cast to \"INT\" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018\n",
      "== DataFrame ==\n",
      "\"cast\" was called from\n",
      "line 6 in cell [9]\n",
      ".\n",
      "25/12/06 18:24:26 WARN BlockManager: Block rdd_89_11 could not be removed as it was not found on disk or in memory\n",
      "25/12/06 18:24:26 ERROR Executor: Exception in task 11.0 in stage 76.0 (TID 438)\n",
      "org.apache.spark.SparkNumberFormatException: [CAST_INVALID_INPUT] The value 'RepÃºblica de Honduras' of the type \"STRING\" cannot be cast to \"INT\" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018\n",
      "== DataFrame ==\n",
      "\"cast\" was called from\n",
      "line 6 in cell [9]\n",
      "\n",
      "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.invalidInputInCastToNumberError(QueryExecutionErrors.scala:145)\n",
      "\tat org.apache.spark.sql.catalyst.util.UTF8StringUtils$.withException(UTF8StringUtils.scala:51)\n",
      "\tat org.apache.spark.sql.catalyst.util.UTF8StringUtils$.toIntExact(UTF8StringUtils.scala:34)\n",
      "\tat org.apache.spark.sql.catalyst.util.UTF8StringUtils.toIntExact(UTF8StringUtils.scala)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:90)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:82)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:294)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:291)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "25/12/06 18:24:26 WARN BlockManager: Putting block rdd_89_3 failed due to exception org.apache.spark.SparkNumberFormatException: [CAST_INVALID_INPUT] The value 'Colombia' of the type \"STRING\" cannot be cast to \"INT\" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018\n",
      "== DataFrame ==\n",
      "\"cast\" was called from\n",
      "line 6 in cell [9]\n",
      ".\n",
      "25/12/06 18:24:26 WARN BlockManager: Block rdd_89_3 could not be removed as it was not found on disk or in memory\n",
      "25/12/06 18:24:26 ERROR Executor: Exception in task 3.0 in stage 76.0 (TID 430)\n",
      "org.apache.spark.SparkNumberFormatException: [CAST_INVALID_INPUT] The value 'Colombia' of the type \"STRING\" cannot be cast to \"INT\" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018\n",
      "== DataFrame ==\n",
      "\"cast\" was called from\n",
      "line 6 in cell [9]\n",
      "\n",
      "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.invalidInputInCastToNumberError(QueryExecutionErrors.scala:145)\n",
      "\tat org.apache.spark.sql.catalyst.util.UTF8StringUtils$.withException(UTF8StringUtils.scala:51)\n",
      "\tat org.apache.spark.sql.catalyst.util.UTF8StringUtils$.toIntExact(UTF8StringUtils.scala:34)\n",
      "\tat org.apache.spark.sql.catalyst.util.UTF8StringUtils.toIntExact(UTF8StringUtils.scala)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:90)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:82)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:294)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:291)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "25/12/06 18:24:26 WARN TaskSetManager: Lost task 10.0 in stage 76.0 (TID 437) (192.168.0.12 executor driver): org.apache.spark.SparkNumberFormatException: [CAST_INVALID_INPUT] The value 'El Salvador' of the type \"STRING\" cannot be cast to \"INT\" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018\n",
      "== DataFrame ==\n",
      "\"cast\" was called from\n",
      "line 6 in cell [9]\n",
      "\n",
      "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.invalidInputInCastToNumberError(QueryExecutionErrors.scala:145)\n",
      "\tat org.apache.spark.sql.catalyst.util.UTF8StringUtils$.withException(UTF8StringUtils.scala:51)\n",
      "\tat org.apache.spark.sql.catalyst.util.UTF8StringUtils$.toIntExact(UTF8StringUtils.scala:34)\n",
      "\tat org.apache.spark.sql.catalyst.util.UTF8StringUtils.toIntExact(UTF8StringUtils.scala)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:90)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:82)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:294)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:291)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "\n",
      "25/12/06 18:24:26 WARN BlockManager: Putting block rdd_89_1 failed due to exception org.apache.spark.TaskKilledException.\n",
      "25/12/06 18:24:26 WARN BlockManager: Putting block rdd_89_6 failed due to exception org.apache.spark.TaskKilledException.\n",
      "25/12/06 18:24:26 WARN BlockManager: Putting block rdd_89_8 failed due to exception org.apache.spark.TaskKilledException.\n",
      "25/12/06 18:24:26 WARN BlockManager: Putting block rdd_89_0 failed due to exception org.apache.spark.TaskKilledException.\n",
      "25/12/06 18:24:26 WARN BlockManager: Putting block rdd_89_9 failed due to exception org.apache.spark.TaskKilledException.\n",
      "25/12/06 18:24:26 WARN BlockManager: Block rdd_89_9 could not be removed as it was not found on disk or in memory\n",
      "25/12/06 18:24:26 WARN BlockManager: Block rdd_89_0 could not be removed as it was not found on disk or in memory\n",
      "25/12/06 18:24:26 WARN TaskSetManager: Lost task 3.0 in stage 76.0 (TID 430) (192.168.0.12 executor driver): org.apache.spark.SparkNumberFormatException: [CAST_INVALID_INPUT] The value 'Colombia' of the type \"STRING\" cannot be cast to \"INT\" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018\n",
      "== DataFrame ==\n",
      "\"cast\" was called from\n",
      "line 6 in cell [9]\n",
      "\n",
      "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.invalidInputInCastToNumberError(QueryExecutionErrors.scala:145)\n",
      "\tat org.apache.spark.sql.catalyst.util.UTF8StringUtils$.withException(UTF8StringUtils.scala:51)\n",
      "\tat org.apache.spark.sql.catalyst.util.UTF8StringUtils$.toIntExact(UTF8StringUtils.scala:34)\n",
      "\tat org.apache.spark.sql.catalyst.util.UTF8StringUtils.toIntExact(UTF8StringUtils.scala)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:90)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:82)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:294)\n",
      "\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:291)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "\n",
      "25/12/06 18:24:26 WARN BlockManager: Putting block rdd_89_2 failed due to exception org.apache.spark.TaskKilledException.\n",
      "25/12/06 18:24:26 WARN BlockManager: Block rdd_89_8 could not be removed as it was not found on disk or in memory\n",
      "25/12/06 18:24:26 WARN BlockManager: Block rdd_89_2 could not be removed as it was not found on disk or in memory\n",
      "25/12/06 18:24:26 WARN BlockManager: Putting block rdd_89_5 failed due to exception org.apache.spark.TaskKilledException.\n",
      "25/12/06 18:24:26 WARN BlockManager: Block rdd_89_5 could not be removed as it was not found on disk or in memory\n",
      "25/12/06 18:24:26 WARN BlockManager: Putting block rdd_89_4 failed due to exception org.apache.spark.TaskKilledException.\n",
      "25/12/06 18:24:26 WARN BlockManager: Block rdd_89_4 could not be removed as it was not found on disk or in memory\n",
      "25/12/06 18:24:26 WARN BlockManager: Block rdd_89_6 could not be removed as it was not found on disk or in memory\n",
      "25/12/06 18:24:26 WARN BlockManager: Block rdd_89_1 could not be removed as it was not found on disk or in memory\n",
      "25/12/06 18:24:26 WARN TaskSetManager: Lost task 0.0 in stage 76.0 (TID 427) (192.168.0.12 executor driver): TaskKilled (Stage cancelled: [CAST_INVALID_INPUT] The value 'RepÃºblica de Honduras' of the type \"STRING\" cannot be cast to \"INT\" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018\n",
      "== DataFrame ==\n",
      "\"cast\" was called from\n",
      "line 6 in cell [9]\n",
      ")\n",
      "25/12/06 18:24:26 WARN TaskSetManager: Lost task 8.0 in stage 76.0 (TID 435) (192.168.0.12 executor driver): TaskKilled (Stage cancelled: [CAST_INVALID_INPUT] The value 'RepÃºblica de Honduras' of the type \"STRING\" cannot be cast to \"INT\" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018\n",
      "== DataFrame ==\n",
      "\"cast\" was called from\n",
      "line 6 in cell [9]\n",
      ")\n",
      "25/12/06 18:24:26 WARN TaskSetManager: Lost task 5.0 in stage 76.0 (TID 432) (192.168.0.12 executor driver): TaskKilled (Stage cancelled: [CAST_INVALID_INPUT] The value 'RepÃºblica de Honduras' of the type \"STRING\" cannot be cast to \"INT\" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018\n",
      "== DataFrame ==\n",
      "\"cast\" was called from\n",
      "line 6 in cell [9]\n",
      ")\n",
      "25/12/06 18:24:26 WARN TaskSetManager: Lost task 9.0 in stage 76.0 (TID 436) (192.168.0.12 executor driver): TaskKilled (Stage cancelled: [CAST_INVALID_INPUT] The value 'RepÃºblica de Honduras' of the type \"STRING\" cannot be cast to \"INT\" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018\n",
      "== DataFrame ==\n",
      "\"cast\" was called from\n",
      "line 6 in cell [9]\n",
      ")\n",
      "25/12/06 18:24:26 WARN TaskSetManager: Lost task 2.0 in stage 76.0 (TID 429) (192.168.0.12 executor driver): TaskKilled (Stage cancelled: [CAST_INVALID_INPUT] The value 'RepÃºblica de Honduras' of the type \"STRING\" cannot be cast to \"INT\" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018\n",
      "== DataFrame ==\n",
      "\"cast\" was called from\n",
      "line 6 in cell [9]\n",
      ")\n",
      "25/12/06 18:24:26 WARN TaskSetManager: Lost task 1.0 in stage 76.0 (TID 428) (192.168.0.12 executor driver): TaskKilled (Stage cancelled: [CAST_INVALID_INPUT] The value 'RepÃºblica de Honduras' of the type \"STRING\" cannot be cast to \"INT\" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018\n",
      "== DataFrame ==\n",
      "\"cast\" was called from\n",
      "line 6 in cell [9]\n",
      ")\n",
      "25/12/06 18:24:26 WARN TaskSetManager: Lost task 6.0 in stage 76.0 (TID 433) (192.168.0.12 executor driver): TaskKilled (Stage cancelled: [CAST_INVALID_INPUT] The value 'RepÃºblica de Honduras' of the type \"STRING\" cannot be cast to \"INT\" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018\n",
      "== DataFrame ==\n",
      "\"cast\" was called from\n",
      "line 6 in cell [9]\n",
      ")\n",
      "25/12/06 18:24:26 WARN BlockManager: Putting block rdd_89_13 failed due to exception org.apache.spark.SparkException: [FAILED_READ_FILE.NO_HINT] Encountered error while reading file file:///home/jair/Escritorio/Big%20Data/Proyectos/Covid/Data/Covid_limpio.csv.  SQLSTATE: KD001.\n",
      "25/12/06 18:24:26 WARN TaskSetManager: Lost task 12.0 in stage 76.0 (TID 439) (192.168.0.12 executor driver): TaskKilled (Stage cancelled: [CAST_INVALID_INPUT] The value 'RepÃºblica de Honduras' of the type \"STRING\" cannot be cast to \"INT\" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018\n",
      "== DataFrame ==\n",
      "\"cast\" was called from\n",
      "line 6 in cell [9]\n",
      ")\n",
      "25/12/06 18:24:26 WARN BlockManager: Block rdd_89_13 could not be removed as it was not found on disk or in memory\n",
      "25/12/06 18:24:26 WARN TaskSetManager: Lost task 4.0 in stage 76.0 (TID 431) (192.168.0.12 executor driver): TaskKilled (Stage cancelled: [CAST_INVALID_INPUT] The value 'RepÃºblica de Honduras' of the type \"STRING\" cannot be cast to \"INT\" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018\n",
      "== DataFrame ==\n",
      "\"cast\" was called from\n",
      "line 6 in cell [9]\n",
      ")\n",
      "25/12/06 18:24:26 WARN TaskSetManager: Lost task 13.0 in stage 76.0 (TID 440) (192.168.0.12 executor driver): TaskKilled (Stage cancelled: [CAST_INVALID_INPUT] The value 'RepÃºblica de Honduras' of the type \"STRING\" cannot be cast to \"INT\" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018\n",
      "== DataFrame ==\n",
      "\"cast\" was called from\n",
      "line 6 in cell [9]\n",
      ")\n",
      "{\"ts\": \"2025-12-06 18:24:26.236\", \"level\": \"ERROR\", \"logger\": \"DataFrameQueryContextLogger\", \"msg\": \"[CAST_INVALID_INPUT] The value 'RepÃºblica de Honduras' of the type \\\"STRING\\\" cannot be cast to \\\"INT\\\" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018\", \"context\": {\"file\": \"line 6 in cell [9]\", \"line\": \"\", \"fragment\": \"cast\", \"errorClass\": \"CAST_INVALID_INPUT\"}, \"exception\": {\"class\": \"Py4JJavaError\", \"msg\": \"An error occurred while calling o831.count.\\n: org.apache.spark.SparkNumberFormatException: [CAST_INVALID_INPUT] The value 'RepÃºblica de Honduras' of the type \\\"STRING\\\" cannot be cast to \\\"INT\\\" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018\\n== DataFrame ==\\n\\\"cast\\\" was called from\\nline 6 in cell [9]\\n\\n\\tat org.apache.spark.sql.errors.QueryExecutionErrors$.invalidInputInCastToNumberError(QueryExecutionErrors.scala:145)\\n\\tat org.apache.spark.sql.catalyst.util.UTF8StringUtils$.withException(UTF8StringUtils.scala:51)\\n\\tat org.apache.spark.sql.catalyst.util.UTF8StringUtils$.toIntExact(UTF8StringUtils.scala:34)\\n\\tat org.apache.spark.sql.catalyst.util.UTF8StringUtils.toIntExact(UTF8StringUtils.scala)\\n\\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\\n\\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\\n\\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)\\n\\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:90)\\n\\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:82)\\n\\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:294)\\n\\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:291)\\n\\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)\\n\\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)\\n\\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)\\n\\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)\\n\\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)\\n\\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)\\n\\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)\\n\\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)\\n\\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\\n\\tat java.base/java.lang.Thread.run(Thread.java:840)\\n\", \"stacktrace\": [{\"class\": null, \"method\": \"deco\", \"file\": \"/home/jair/anaconda3/envs/BigData/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py\", \"line\": \"282\"}, {\"class\": null, \"method\": \"get_return_value\", \"file\": \"/home/jair/anaconda3/envs/BigData/lib/python3.11/site-packages/py4j/protocol.py\", \"line\": \"327\"}]}}\n"
     ]
    },
    {
     "ename": "NumberFormatException",
     "evalue": "[CAST_INVALID_INPUT] The value 'RepÃºblica de Honduras' of the type \"STRING\" cannot be cast to \"INT\" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018\n== DataFrame ==\n\"cast\" was called from\nline 6 in cell [9]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNumberFormatException\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# 3. Contar mujeres con clasificación positiva usando la columna casteada\u001b[39;00m\n\u001b[32m     10\u001b[39m positivos_covid = [\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m]\n\u001b[32m     11\u001b[39m mujeres_positivas = \u001b[43mdf_validos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mSEXO\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m&\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mCLASIFICACION_FINAL_INT\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43misin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositivos_covid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(mujeres_positivas)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/BigData/lib/python3.11/site-packages/pyspark/sql/classic/dataframe.py:439\u001b[39m, in \u001b[36mDataFrame.count\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    438\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcount\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m439\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/BigData/lib/python3.11/site-packages/py4j/java_gateway.py:1362\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1356\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1357\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1358\u001b[39m     args_command +\\\n\u001b[32m   1359\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1361\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1362\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1363\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1365\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1366\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/BigData/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py:288\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    284\u001b[39m converted = convert_exception(e.java_exception)\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[32m    286\u001b[39m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[32m    287\u001b[39m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    290\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mNumberFormatException\u001b[39m: [CAST_INVALID_INPUT] The value 'RepÃºblica de Honduras' of the type \"STRING\" cannot be cast to \"INT\" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018\n== DataFrame ==\n\"cast\" was called from\nline 6 in cell [9]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, expr\n",
    "\n",
    "# 1. Convertir a bigint usando try_cast\n",
    "df = df.withColumn(\"CLASIFICACION_FINAL_INT\", expr(\"try_cast(CLASIFICACION_FINAL as bigint)\"))\n",
    "\n",
    "# 2. Filtrar solo valores válidos y materializar\n",
    "df_validos = df.filter(col(\"CLASIFICACION_FINAL_INT\").isNotNull()).cache()\n",
    "\n",
    "# 3. Contar mujeres con clasificación positiva usando la columna casteada\n",
    "positivos_covid = [1, 2, 3]\n",
    "mujeres_positivas = df_validos.filter(\n",
    "    (col('SEXO') == 1) & (col('CLASIFICACION_FINAL_INT').isin(positivos_covid))).count()\n",
    "\n",
    "print(mujeres_positivas)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BigData",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
